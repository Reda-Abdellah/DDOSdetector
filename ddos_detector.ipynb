{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we do imports , we need numpy pandas sklearn pyasn installed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pyasn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we first read our csv using pandas\n",
    "data=pd.read_csv('reduced.csv',header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data is structured by columns as follow : timestamp of the end of a flow (te), duration of flow (td), source IP address (sa), destination IP (da), source port (sp), destination port (dp), protocol (pr), flags (flg), forwarding status (fwd), type of service (stos), packets exchanged in the flow (pkt), and their corresponding number of bytes (byt).\n",
    "\n",
    "we decided to use some columns and not the others after running tests, it turns out that using these features will train a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we extract numerical data\n",
    "X_numerical=data[[2,3,9,11,1]]\n",
    "\n",
    "#we extract categorical data using dummies\n",
    "X_categorical=pd.get_dummies(data[[5]])\n",
    "Y_labled=pd.get_dummies(data[[12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we are interrested only with the dos column\n",
    "Y_labled=Y_labled[['12_dos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#casting to numpy arrays and combining matrix\n",
    "\n",
    "Y=np.array(Y_labled)\n",
    "X=np.hstack((np.array(X_categorical),np.array(X_numerical)))\n",
    "X=np.hstack((X ,  np.array(data[[7]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reda/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# reducing\n",
    "#depending on your computing power , you may want to run this cell twice\n",
    "a, X, b, Y = train_test_split(X, Y, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.A..SF' '....S.' '.A..SF' ... '.A....' '...RS.' '.AP.S.']\n"
     ]
    }
   ],
   "source": [
    "aspf=X[:,-1]\n",
    "print(aspf)\n",
    "#dimension \n",
    "row_size=aspf.size\n",
    "#number of caracteres\n",
    "nb_attr=len(aspf[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we want to transform the flag to more logical form , using one hot encoding\n",
    "ASPF=np.ones((row_size,nb_attr))\n",
    "for i in range(0,row_size):\n",
    "    for j in range(0,nb_attr):\n",
    "        if aspf[i][j]=='.':\n",
    "            ASPF[i,j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X[:,:-1]\n",
    "X=np.hstack((X,ASPF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we want to transform IP adresses to ASN\n",
    "IP=np.zeros((row_size,2))\n",
    "asndb = pyasn.pyasn('ipasn_20140513.dat')\n",
    "\n",
    "\n",
    "for i in range(0,row_size):\n",
    "    ASN=asndb.lookup(X[i,1])[0]\n",
    "    if str(ASN)=='None' :\n",
    "        ASN=0\n",
    "    IP[i,0]=ASN\n",
    "    ASN=asndb.lookup(X[i,2])[0]\n",
    "    if str(ASN)=='None' :\n",
    "        ASN=0\n",
    "    IP[i,1]=ASN\n",
    "\n",
    " \n",
    "X=np.hstack((X[:,0:1],X[:,3:]))\n",
    "X=np.hstack((X,IP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reda/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting kneighbor to the Training set\n",
    "classifier = KNeighborsClassifier(1, n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reda/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14127     7]\n",
      " [    3   863]]\n"
     ]
    }
   ],
   "source": [
    "print(\"the confusion matrix on the test set\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.A....' '.A....' '.A....' ... '.AP.SF' '.AP.SF' '.A...F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reda/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#now, we will test our model on a different part of the dataset\n",
    "#we have to preprocess it the same way\n",
    "\n",
    "print(\"now we will use our trained model on the another sub-dataset\")\n",
    "data2=pd.read_csv('reduced3.csv',header=None)\n",
    "\n",
    "\n",
    "X_numerical2=data2[[2,3,9,11,1]]\n",
    "\n",
    "#dummies\n",
    "X_categorical2=pd.get_dummies(data2[[5]])\n",
    "Y_labled2=pd.get_dummies(data2[[12]])\n",
    "\n",
    "\n",
    "#on garde juse dos et normal\n",
    "Y_labled2=Y_labled2[['12_dos']]\n",
    "\n",
    "\n",
    "#casting to numpy arrays and combining matrix\n",
    "\n",
    "Y2=np.array(Y_labled2)\n",
    "X2=np.hstack((np.array(X_categorical2),np.array(X_numerical2)))\n",
    "X2=np.hstack((X2 ,  np.array(data2[[7]])))\n",
    "\n",
    "\n",
    "# reducing\n",
    "a, X2, b, Y2 = train_test_split(X2, Y2, test_size = 0.10, random_state = 0)\n",
    "\n",
    "aspf2=X2[:,-1]\n",
    "print(aspf2)\n",
    "\n",
    "#dimension \n",
    "row_size2=aspf2.size\n",
    "#number of caracteres\n",
    "nb_attr2=len(aspf2[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ASPF2=np.ones((row_size2,nb_attr2))\n",
    "for i in range(0,row_size2):\n",
    "    for j in range(0,nb_attr2):\n",
    "        if aspf2[i][j]=='.':\n",
    "            ASPF2[i,j]=0\n",
    "\n",
    "\n",
    "\n",
    "X2=X2[:,:-1]\n",
    "X2=np.hstack((X2,ASPF2))\n",
    "\n",
    "\n",
    "#for ip\n",
    "IP2=np.zeros((row_size2,2))\n",
    "asndb2 = pyasn.pyasn('ipasn_20140513.dat')\n",
    "\n",
    "\n",
    "for i in range(0,row_size2):\n",
    "    ASN2=asndb2.lookup(X2[i,1])[0]\n",
    "    if str(ASN2)=='None' :\n",
    "        ASN2=0\n",
    "    IP2[i,0]=ASN2\n",
    "    ASN2=asndb2.lookup(X2[i,2])[0]\n",
    "    if str(ASN2)=='None' :\n",
    "        ASN2=0\n",
    "    IP2[i,1]=ASN2\n",
    "\n",
    " \n",
    "X2=np.hstack((X2[:,0:1],X2[:,3:]))\n",
    "X2=np.hstack((X2,IP2))\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "X2 = sc.fit_transform(X2)\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred2 = classifier.predict(X2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37837    49]\n",
      " [   39  2075]]\n"
     ]
    }
   ],
   "source": [
    "#print the confusion matrix\n",
    "cm2 = confusion_matrix(Y2, y_pred2)\n",
    "print(\"the confusion matrix on another part of the dataset\")\n",
    "\n",
    "#the matrix bellow represents : \n",
    "#[[true negative ,false positive]\n",
    "#[false negative ,true positive]]\n",
    "\n",
    "print(cm2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
